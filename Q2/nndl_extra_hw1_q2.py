# -*- coding: utf-8 -*-
"""NNDL EXTRA HW1 Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1woiBfSmdJFQGVOqRiyj6zNCQljViNaf4

# Semantic Segmentation

## Download data and transfer it to drive
"""

!wget https://s3.amazonaws.com/fast-ai-imagelocal/camvid.tgz

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cp camvid.tgz /content/drive/MyDrive

"""## U-Net Implementation

### Import libraries
"""

import os
import torch
import random
import shutil
import cv2
import torchvision
import matplotlib.pyplot as plt
import numpy as np
from torch import nn, optim
from torch.utils.data import Dataset as BaseDataset, DataLoader

"""### U-Net Class"""

class UNet(nn.Module):
  def __init__(self):
      super().__init__()
      self.conv1 = nn.Conv2d(3, 64, 3)
      self.conv2 = nn.Conv2d(64, 64, 3)
      self.conv3 = nn.Conv2d(64, 128, 3)
      self.conv4 = nn.Conv2d(128, 128, 3)
      self.conv5 = nn.Conv2d(128, 256, 3)
      self.conv6 = nn.Conv2d(256, 256, 3)
      self.conv7 = nn.Conv2d(256, 512, 3)
      self.conv8 = nn.Conv2d(512, 512, 3)
      self.conv9 = nn.Conv2d(512, 1024, 3)
      self.conv10 = nn.Conv2d(1024, 1024, 3)
      self.conv11 = nn.Conv2d(1024, 512, 3)
      self.conv12 = nn.Conv2d(512, 512, 3)
      self.conv13 = nn.Conv2d(512, 256, 3)
      self.conv14 = nn.Conv2d(256, 256, 3)
      self.conv15 = nn.Conv2d(256, 128, 3)
      self.conv16 = nn.Conv2d(128, 128, 3)
      self.conv17 = nn.Conv2d(128, 64, 3)
      self.conv18 = nn.Conv2d(64, 64, 3)
      self.pool = nn.MaxPool2d(2, 2)
      self.up = nn.Upsample(scale_factor=2, mode='nearest')
      self.conv_t1 = nn.ConvTranspose2d(1024, 512, 2, 2)
      self.conv_t2 = nn.ConvTranspose2d(512, 256, 2, 2)
      self.conv_t3 = nn.ConvTranspose2d(256, 128, 2, 2)
      self.conv_t4 = nn.ConvTranspose2d(128, 64, 2, 2)
      self.final_conv = nn.Conv2d(64, 256, 1)
      self.relu = nn.ReLU()

  def forward(self, x):
      x = self.relu(self.conv2(self.relu(self.conv1(x))))
      x1 = torchvision.transforms.CenterCrop([88, 88])(x)
      x = self.pool(x)
      x = self.relu(self.conv4(self.relu(self.conv3(x))))
      x2 = torchvision.transforms.CenterCrop([48, 48])(x)
      x = self.pool(x)
      x = self.relu(self.conv6(self.relu(self.conv5(x))))
      x3 = torchvision.transforms.CenterCrop([28, 28])(x)
      x = self.pool(x)
      x = self.relu(self.conv8(self.relu(self.conv7(x))))
      x4 = torchvision.transforms.CenterCrop([18, 18])(x)
      x = self.pool(x)
      x = self.relu(self.conv10(self.relu(self.conv9(x))))
      x = self.conv_t1(x)
      x = torch.cat((x4, x), dim = 1)
      x = self.relu(self.conv12(self.relu(self.conv11(x))))
      x = self.conv_t2(x)
      x = torch.cat((x3, x), dim = 1)
      x = self.relu(self.conv14(self.relu(self.conv13(x))))
      x = self.conv_t3(x)
      x = torch.cat((x2, x), dim = 1)
      x = self.relu(self.conv16(self.relu(self.conv15(x))))
      x = self.conv_t4(x)
      x = torch.cat((x1, x), dim = 1)
      x = self.relu(self.conv18(self.relu(self.conv17(x))))
      x = self.final_conv(x)
      del x1
      del x2
      del x3
      del x4
      return x

"""## Make data ready 
+ Unzip data and explore
+ Train Test Split
+ Create dataloader
"""

!tar -xvzf camvid.tgz

"""### Rename targets"""

label_path = '/content/camvid/labels'
labels = os.listdir(label_path)
 
for label in labels:
    old_label = str(label)
    new_label = label.replace('_P.png','.png')
    os.rename(os.path.join(label_path, old_label),os.path.join(label_path, new_label))

!rm -r /content/camvid/train_data/
!rm -r /content/camvid/train_targets/
!rm -r /content/camvid/test_data/
!rm -r /content/camvid/test_targets/
!rm -r /content/camvid/images/.ipynb_checkpoints
!rm /content/camvid/images/test.txt

"""## Split data in train and test"""

base_path = '/content/camvid/'
images_folder = 'images'
labels_folder  = 'labels'
 
image_names = os.listdir(os.path.join(base_path, images_folder))
images_count = len(image_names)
train_percentage = int(images_count*0.7)

random.shuffle(image_names)
 
train_images_list = image_names[:train_percentage]
test_images_list = image_names[train_percentage:images_count]

train_data_path = os.path.join(base_path,'train_data')
train_targets_path  = os.path.join(base_path,'train_targets')
if not os.path.exists(train_data_path):
    os.mkdir(train_data_path )
if not os.path.exists(train_targets_path):
    os.mkdir(train_targets_path)

for image in train_images_list:
    shutil.copy(os.path.join(base_path, images_folder, image), os.path.join(train_data_path, image))
    shutil.copy(os.path.join(base_path, labels_folder, image), os.path.join(train_targets_path, image))

test_data_path = os.path.join(base_path,'test_data')
test_targets_path  = os.path.join(base_path,'test_targets')
if not os.path.exists(test_data_path):
    os.mkdir(test_data_path )
if not os.path.exists(test_targets_path):
    os.mkdir(test_targets_path)

for image in test_images_list:
    shutil.copy(os.path.join(base_path, images_folder, image), os.path.join(test_data_path, image))
    shutil.copy(os.path.join(base_path, labels_folder, image), os.path.join(test_targets_path, image))

"""### Custom Dataloader"""

class Dataset(BaseDataset):
    def __init__(self, data_dir, label_dir):
        self.selected_ids = os.listdir(data_dir)
        self.data = [os.path.join(data_dir, image_id) for image_id in self.selected_ids]
        self.target = [os.path.join(label_dir, image_id) for image_id in self.selected_ids]

    def __getitem__(self, index):
        image = cv2.imread(self.data[index])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        label = cv2.imread(self.target[index], 0)
        image = cv2.resize(image, (280, 280)) 
        label = cv2.resize(label, (84, 84))

        image_height, image_width, image_dim = image.shape
        image = image.reshape(image_dim, image_height, image_width)

        label_height, label_width = label.shape
        label = label.reshape(1, label_height, label_width)
        return image, label
        
    def __len__(self):
        return len(self.selected_ids)

train_dataset = Dataset(train_data_path, train_targets_path)
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)

test_dataset = Dataset(test_data_path, test_targets_path)
test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)

"""## Train and Test Network"""

def test(model, test_set, loss_function):
  with torch.no_grad():
    batches_test_loss = []
    for features, target in test_set:
      features, target = features.cuda(), target.cuda()
      output = model(features.float())
      loss = loss_function(output, target.long().squeeze(1)).item()
      batches_test_loss.append(loss)
  return np.mean(batches_test_loss)

def train_and_test(model, train_set, test_set, epochs_num, optimizer, loss_function):
  epochs_train_loss = []
  epochs_test_loss = []
  for epoch in range(epochs_num):
    print(epoch)
    batches_train_loss = []
    for features, targets in train_set:
      features, targets = features.cuda(), targets.cuda()
      optimizer.zero_grad()
      output = model(features.float())
      loss = loss_function(output, targets.long().squeeze(1))
      loss.backward()
      optimizer.step()
      batches_train_loss.append(loss.item())
    epochs_train_loss.append(np.mean(batches_train_loss))
    test_loss = test(model, test_set, loss_function)
    epochs_test_loss.append(test_loss)
  return epochs_train_loss, epochs_test_loss

"""### Plot function"""

def plot_losses(epochs_train_loss, epochs_test_loss, epochs_num, loss_type):
  x_axis = range(1, epochs_num+1)
  legends = ['train', 'test']
  x_label = 'Epoch'
  plt.plot(x_axis, epochs_train_loss, epochs_test_loss)
  plt.title(loss_type)
  plt.xlabel(x_label)
  plt.legend(legends)
  plt.show()

"""## Run Train Network"""

import gc
del u_net
gc.collect()
torch.cuda.empty_cache()

epochs_num = 100
u_net = UNet()
u_net.cuda()
optimizer = optim.Adam(u_net.parameters(), lr=0.0001, weight_decay=1e-8)
loss_function = nn.CrossEntropyLoss()
epochs_train_loss, epochs_test_loss = train_and_test(u_net, train_loader, test_loader, epochs_num, optimizer, loss_function)
print(epochs_train_loss)
print(epochs_test_loss)
plot_losses(epochs_train_loss, epochs_test_loss, epochs_num, "Cross Entropy")
torch.save(u_net, '/content/drive/MyDrive/weights.pt')

"""## Load Trained model"""

u_net = torch.load('/content/drive/MyDrive/weights.pt')
u_net

"""## Predict image with traines model"""

def predict(model, data_set):
  with torch.no_grad():
    for features, targets in data_set:
      features, targets = features.cuda(), targets.cuda()
      output = model(features.float())
      prediction = output.argmax(1)
      return prediction, features

predictions, inputs = predict(u_net, test_loader)
for pred in predictions:
  cv2_imshow(pred.cpu().detach().numpy())
for inp in inputs:
  inp = inp.cpu().detach().numpy()
  cv2_imshow(inp.reshape((280, 280, 3)))

"""### Image playground"""

from google.colab.patches import cv2_imshow

image = cv2.imread('/content/camvid/images/0001TP_006690.png')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
label = cv2.imread('/content/camvid/labels/0001TP_006690.png')
cv2_imshow(image)
cv2_imshow(label)
# image_height, image_width, image_dim = image.shape
# image = image.reshape(image_dim, image_height, image_width)
image = cv2.resize(image, (280, 280))
cv2_imshow(image)
label = cv2.resize(label, (84, 84))
cv2_imshow(label)

"""## Train to best epoch"""

epochs_num = 40
u_net2 = UNet()
u_net2.cuda()
optimizer2 = optim.Adam(u_net2.parameters(), lr=0.0001, weight_decay=1e-8)
loss_function2 = nn.CrossEntropyLoss()
epochs_train_loss2, epochs_test_loss2 = train_and_test(u_net2, train_loader, test_loader, epochs_num, optimizer2, loss_function2)
plot_losses(epochs_train_loss2, epochs_test_loss2, epochs_num, "Cross Entropy")
torch.save(u_net2, '/content/drive/MyDrive/best_weights.pt')

predictions, inputs = predict(u_net2, test_loader)
for pred in predictions:
  cv2_imshow(pred.cpu().detach().numpy())
for inp in inputs:
  inp = inp.cpu().detach().numpy()
  cv2_imshow(inp.reshape((280, 280, 3)))